---
title: Bayes Theorem
icon: circle-check
---

Bayes' Theorem is a fundamental principle in probability theory that describes how to update our beliefs based on new evidence. The theorem states that P(A|B) = P(B|A) Ã— P(A) / P(B), where P(A|B) is the **posterior probability** (our updated belief about A after observing B), P(A) is the **prior probability** (our initial belief about A before seeing any evidence), P(B|A) is the **likelihood** (the probability of observing evidence B given that A is true), and P(B) is the **marginal probability** (the total probability of observing B). In essence, Bayes' Theorem allows us to reverse conditional probabilities and update our hypotheses as new data becomes available, making it invaluable in fields like machine learning, medical diagnosis, and statistical inference.
